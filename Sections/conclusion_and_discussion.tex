Video based job interviews and resumes are becoming increasingly popular methods for organizations to adopt in their hiring process. Automatic personality trait and mood could vastly accelerate and support this process. As the literature illustrates, personality traits and mood are important factors that influence the decision to invite an applicant to an interview. Creating such automated systems can only be done however, if the trained models are highly accurate and do not show bias. Therefore, the experiments done in this thesis are to compare and improve classification models using extracted video features which can lead to better automated job screening systems.

Several experiments have been done using our data-set, ranging from classification of dimensions to creating explainable models like decision trees. The ELM algorithm has proven to be an accurate to model mood and likeability dimensions from a set of video features. With UAR scores of up to 57\%, the performance was considerably above the chance level of 33\%. Further, the results show ELM models have also proven to be more accurate than the widely used support vector machine algorithm. Also, a moderate correlation has been found between the interview invitation variable and the mood and likeability dimensions. Despite this correlation, the decision tree model and feature importance experiment show that valence and arousal play a minor role in the prediction of the interview invitation variable. The personality traits, especially openness, agreeableness and conscientiousness show to be more important factors in predicting the interview invitation variable. The resulting decision tree could be used to help job recruiter in the job screening process. However, it is strongly recommended that more modalities and dimensions should be explored before such a classification system should be used in the wild. The experiments done in this thesis only utilized video features from the video clips in the data-set. However, video resumes obviously also include acoustics which should be used in combination of video features to create more accurate models. 

A great deal of future research can be done with the data-set that was used for this thesis. For example, the data-set is also annotated for ethnicity, age groups, gender and background music. These variables are annotated using a categorical scale. Therefore the data-set could be split into different categories regarding these dimensions which could result in interesting new decision trees and model results. It could also expose biases towards the different categories of these dimensions from the annotators, or expose a bias a job recruiter might have. Also, in this thesis only the video features are used to train the models. Also, for the modeling stage only 960 samples were used of the available 10,000 video clips. If a larger sample size, if not all video clips, would also be annotated for the mood and likeability dimensions, the performance of the classifications model could be improved. This could also lead to better explainability models. The bias of the annotators regarding ethnicity, age groups and gender was also not explored. Further analysis of this data could expose biases and therefore also illustrate biases in the classification models. 